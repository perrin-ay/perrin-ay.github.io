---
layout: posts
title: "Against Schupbach and Sprenger’s bayesian account of explanatory power"
description: "Against Schupbach and Sprenger’s bayesian account of explanatory power"
date: 2023-01-29T07:00:00-07:00
category: Epistemology
tags: Epistemology
---
![TE image](/images/ep2.jfif){: style="width:400px; float:center;"}

[Here](https://perrin-ay.github.io/epistemology/2022/12/02/Bayesian-accounts-of-explanatory-power.html){:target="_blank"}, I had introduced explanatory reasoning and explanatory power (EP). I went on to discuss Peirce’s three step inferential pattern (PI) that captures an intuitive sense in which we evaluate EP. I also covered Schupbach and Sprenger’s (S&S’s) proposal which offers a Bayesian approach to accounting EP in the context of PI.

In this article I explore the role of surprise in EP within the inferential framework of PI.This is a natural starting point since the inferential pattern of PI gets off the ground with surprise. Following this I pose my argument against S&S’s proposal, exposing the fact that degrees of belief in explanandum (E) are already equal to 1 once the agent encounters E. This undermines S&S’s account since they build on the assumption that the reduction in surprise is directly correlated to increasing degrees of belief in E.

## Beliefs, surprise, and abductive triggers

With this section I begin my analysis of EP within the inferential framework of PI, starting with an analysis of surprise taken in the context of PI. This is a natural starting point since the inferential pattern of PI gets off the ground with surprise. 

Within the inferential framework of PI, explanatory reasoning begins with encountering a surprising fact. According to PI, there is no ( no need for) reasoning, if there is no surprising fact encountered. The surprising fact is the “abductive trigger” (Aliseda 1997) as it triggers abductive inference (“Abduction” or “abductive inference” is Peirce’s label for explanatory reasoning captured in PI) into action, by requiring an explanation for it. Within the framework of PI, I take the “surpriseness” in an encountered fact to be what determines whether it is an explanandum and requiring explanation seeking.

But the degree of surprise in the encountered fact is relative to the agent encountering it. This makes intuitive sense as encountering a particular fact might be surprising to some while not to others, since each agent brings their own background body of knowledge and system of beliefs. One’s background knowledge provides the epistemic basis for one’s beliefs (Pritchard 2017) and different people bring to bear different beliefs to any given situation based on their own background knowledge at that point in time. 

The beliefs an agent brings to bear in a situation, represents her subjective epistemic stance and expectations for that situation. Upon encountering new facts, she may find them surprising when those beliefs do not contain sufficiently powerful explanations for them. Thereby the agent's measure of surprise in encountered facts is based on the beliefs she held just prior to encountering them. A high degree of surprise in the encountered fact determines its status as an explanandum and the abductive trigger for the explanation seeking inferential practice expressed in PI to minimize that surprise.

The dynamics of this can be expressed as follows:

1) Time t1 is temporally prior to time t2.

2) At time t1, agent A holds the epistemic stance and expectations represented by beliefs “pb1” for a given situation.

3) At time t2,  A encounters some fact E in that situation.


Whether E is surprising to A depends on pb1. If pb1 can explain E i.e., pb1 contains high degrees of EP over E, which give A reasons to expect E,  then A would not find E surprising . However, if pb1 cannot suitably explain E, and provides little to no reason to expect it, then A would find E surprising and an abductive trigger.

To summarize, I have tried to highlight two characteristics of surprise so far:

First, that surprise in a fact is subjective and determined by the agent's held beliefs for the situation where she encountered the fact. These beliefs represent her epistemic stance and expectations just prior to encountering the fact. 

Second, that the agent finds the fact surprising when those beliefs do not contain explanations of suitable EP over it and provide little to no reason to expect it. 

I take (2) to be true pro tanto we are concerned with the brand of explanatory reasoning captured by PI. In PI, the inferential pattern begins with surprise in E, and concludes with locating H that reduces that surprise by virtue of having EP over it. If the agent's beliefs had already included suitable explanations like H, there would have been no surprise in E ( since H gives reasons to expect E) and no trigger for PI inferential practice of seeking an explanation for E to minimize the surprise in it.

This lays some groundwork for my proposal that I cover here. In the next section I argue what is problematic with S&S’s approach and the questions that any Bayesian approach to PI must answer.


## Argument against Schupbach & Sprenger’s approach 
As laid out in section 1.3, S&S’s probabilistic treatment of surprise in E consists in taking the probability of E with the Bayesian interpretation which assumes this probability function to represent psychological degrees of belief in E. They formalize PI with the inequality condition ```P(E) < P(E|H)```, where H has EP over E, when the subjective degrees of belief in E given H is greater than what it was without H, and use this in their PR condition to produce an account of EP.  

S&S’s Bayesian analysis tracks the shifts in the agent’s surprise in E strictly as the shifts in the agent's degrees of belief in E. But it is trivially true that upon encountering some fact directly, our degrees of belief or probability of it are equal to one. For example, consider Lipton’s vignette from section 1.1 again, “Faced with tracks in the snow of a certain peculiar shape, I infer that a person on snowshoes has recently passed this way.”  Lipton is surprised to observe the “tracks in the snow” (explanandum E) and infers to the explanans H that “a person on snowshoes passed this way”. But Lipton sees E, thus knows that E ( knows that there are tracks in the snow) and his degrees of belief in E equal 1, i.e., P(E) = 1. His degrees of belief in E are the highest they can be ( since probability of something cannot be more than 1) and cannot be increased any further by conditioning on H. 

To take another example that brings this into sharp relief, consider witnessing snow and hail in the Saharan summer. This is very surprising, as the Sahara is an African desert and deserts have hot climates and very low precipitation year-round. And one may infer the hypothesis of  “climate change” to explain this surprising E of observing snow and hail. But again, the agent directly witnesses and knows that the observation E obtains, and so her degrees of belief in E and the probability of E is already equal to 1 and cannot be improved upon. 

But even though we know that E , the “tracks in the snow” in Lipton’s case and the “snow & hail” of the Saharan desert, obtain with the probability of 1, these examples still capture the sense in which explanatory reasoning is talked about in PI. In both these examples, we begin with surprise, and then explanatory considerations take over to guide inference, which concludes in the explanatory hypothesis ( explanans) of “ a person recently walked this way” and “climate change” respectively, thereby reducing the surprise in their respective explanandum’s. 

Given the foregoing, there is clearly a sense in which the explanans (a person recently walked this way) reduces the surprise in the explanandum (tracks in the snow) since it gives reason to expect it, but the inequality ```P(E) < P(E|H)``` as advocated by S&S doesn't appear to hold as a Bayesian probabilistic formalization of it. To quote S&S:

“ if h decreases the degree to which e is surprising, we represent this with the inequality ```Pr(e) < Pr(e|h)```”

This is because the inequality expression takes the agents' degrees of belief in E, but these are already at probability estimates of 1 since the agents know that E happened. 

So the question arises, since we take PI to capture a legitimate and common deployment of explanatory reasoning, but from my arguments in the foregoing, S&S’s Bayesian formulation of it in terms of degrees of belief in E is problematic, what is the proper Bayesian approach to formalizing the condition of PI, which degrees of beliefs and probability estimate should we be interested in and how are the agents degrees of belief related to surprise and the reduction of it in PI? The next section introduces my proposal and then goes into detail formulating a new Bayesian approach that attempts to answer these questions. 




