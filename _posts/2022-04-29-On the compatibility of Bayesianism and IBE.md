---
layout: posts
title: "On the compatibility of Bayesianism and IBE"
description: "On the compatibility of Bayesianism and IBE"
date: 2022-04-29T07:00:00-07:00
category: Epistemology
tags: Epistemology
---
![TE image](/images/IBE.jfif){: style="width:400px; float:center;"}


### 1. Introduction
Bayesianism and Inference to the best explanation (IBE) are two popular, yet distinct modes of making scientific inference. The question arises - are they related or compatible ? In this article I argue that they are compatible. I conclude that they not only yield similar results, but that some explanatory considerations of IBE are inherent to bayesianism.

The layout of this article is as follows. In 1.1, I introduce IBE and bayesian reasoning and in 1.2, I advance the desiderata for compatibility. In section 2.1, I discuss Weisberg’s compatibility approach. Weisberg argues for compatibility by constraining objective bayesian priors to meet explanatory demands and in 2.2, I forward my objections to this. In 3.1, I make my argument for explanatory power in reference to Peirce’s notion of abduction and in 3.2, I show that this measure of explanatory power is equivalent to how explanatory goodness is assessed in IBE. In 4.1, I show compatibility by locating my measure of explanatory power in the bayes theorem , and in 4.2, I show how the explanatory virtue of simplicity is inherently implemented by bayesianism. 


### 1.1 IBE & bayesianism
Here I introduce the general notion of reasoning via IBE and bayesianism.

IBE is typically formalized as a two-step inferential operation (Lipton 2004, Vogel 1998)
Generate a potential set of competing explanations for a fact or body of facts (explanandum F). 
From this set of explanatory hypotheses, choose the best explanation for F. 

Lipton states that explanatory goodness or the ‘loveliness’ of an explanation is determined by the degree of understanding it provides, and the explanation that confers the most understanding, if true, is the loveliest and thereby the best explanation. Loveliness is the grounds to rank and judge preferences among the set of explanations. Lipton contends that explanatory considerations that mark loveliness can be found in explanatory virtues such as simplicity. (Lipton 2004)

Bayesianism takes rational agents to have degrees of belief with respect to hypotheses in a hypothesis space H, and modeled as a probability density function over H. Per Bayes theorem, when new data is obtained, rational agents ought to update their prior degrees of belief to a posterior, by conditionalizing it to the new data (Gillies 2000).

Where , P(h) is the prior probability of the hypothesis ‘h’, P(e) is the expectedness/probability of the data ‘e’, P(e|h) is the likelihood of ‘e’ given ‘h’, and P(h|e) is the posterior probability of ‘h’ given ‘e’. The degrees of belief for each hypothesis in H is updated in this way, and the posterior probabilities are used to determine hypothesis preference within H, with the most probable posterior deemed the best of the lot.
1.2 The challenge for compatibilists 
Compatibility advocates need to show that IBE and bayesianism usually deliver similar judgments in hypothesis preference and selection. A stronger compatibilist position asks that in addition to yielding similar judgments, explanatory character of IBE be located within bayesianism. 

Thus the **strong compatibilist desiderata** is:

Show that IBE and bayesianism usually leads to similar judgments.

Show that some explanatory considerations that are typical of IBE, can be found within bayesianism.



### 2. Compatibility by constraining priors 
In this section I first discuss the compatibilist strategy that suggests constraining objective priors with explanatory considerations. In the second subsection I argue that such an approach is unsuccessful in showing compatibility, since it ignores the conditionalization component of bayesianism and also does not explicate any explanatory considerations that are naturally inherent to bayesianism.


### 2.1 Weisberg’s approach
Some philosophers (Huemer 2009, Weisberg 2009) have advocated for a compatibilist approach by integrating explanatory considerations of IBE into constraining objective bayesian priors. Such an approach is usually reserved for objective bayesianism , which already holds that priors must be constrained by some principle(Jaynes & Bretthorst 2003). Weisberg argues that explanatory considerations that we take in IBE be used to directly determine hypotheses prior probabilities or be used in a supplemental manner to traditional objective bayesian constraints on the priors. He contends that this aligns IBE and bayesianism to provide similar judgments on hypothesis preference and selection.

For example, Weisberg notes that White’s (White 2005) solution to the grue paradox (Goodman 1965) in bayesianism was to constrain priors by explanatory virtues. The grue paradox posits two competing hypotheses and asks which of the two is the more likely,  green-hypothesis = “ all emeralds are green” or the grue-hypothesis=” all emeralds are green until year X, and blue afterwards”, where any future year can be slotted for year X. Since the likelihood of observing a green emerald now is the same for both hypotheses, their respective posterior probabilities are equal to their respective prior probabilities. Based on its explanatory virtues of stability and simplicity over the grue-hypothesis, the green-hypothesis is assigned a higher prior which means a higher and more probable posterior for it. This matches IBE’s verdict which picks the green-hypothesis, the lovelier explanation of the two, owing to its explanatory virtues of stability and simplicity.  And Weisberg contends that in other cases as well, objective bayesianism can similarly be shown to correspond with results of IBE.


### 2.2 Objections to Weisberg 
Explanatory considerations in IBE consider all data i.e.background knowledge, past data and the new data, when passing judgments on hypotheses. But Weisberg's approach with objective bayesianism only focuses on prior probabilities of hypotheses and ignores P(e|h), which is a crucial step in conditionalizing probabilities to new data and it is how degrees of belief are updated in bayesianism. 

Collecting new data and evidence is part and parcel of empirical testing but Weibergs approach ignores the component in the bayes theorem that realizes the relation between new pieces of evidence and hypotheses. Whether the likelihood of new data, given the truth of a hypothesis, is high or low, is not part of Weisberg’s accounting. Not accounting for how new data fares in relation to hypotheses ```(P(e|h) in the bayes theorem)``` in terms of explanatory considerations, arguably leaves it untethered and free to diverge from any explanatory related constraints. And since the posterior probability of a hypothesis is the product of ```P(h) and P(e|h)```, Weisberg’s account also needs to show ```P(e|h)``` to have explanatory character for posterior probabilities to not diverge from verdicts of IBE.

Another problem with Weisberg's approach is that it tries to address questions on how to adapt bayesianism such that it is compatible with IBE, rather than explaining how bayesianism is already compatible with IBE. It fails to show that some explanatory considerations of IBE are an inherent part of bayesianism and thereby does not motivate the strong compatibilist position.


### 3 Explanatory power 
In this section, following Peirce I first derive a probabilistic measure of explanatory power as the relative change of expectedness in the explanandum that a hypothesis brings about. In the second subsection I show that this measure of explanatory power is consistent with judgments of explanatory goodness in IBE.

### 3.1 Abduction and Explanatory power 
 Following Peirce, abduction can be described as (Fann 1970):

“The surprising fact, E, is observed; 
But if H were true, E would be a matter of course, 
Hence, there is reason to suspect that H is true” 

So abduction starts with an unexpected and surprising fact, this the explanandum E and can be  labeled as the ‘abductive trigger’ ( Aliseda 1997). The abductive trigger kicks off a train of reasoning to find the hypothesis H that explains E, rendering it no longer surprising and thereby expected and “a matter of course”. 

The abductive trigger is relative to reasoners. Some reasoners might find a new fact surprising, while others may not, based on their respective background knowledge. And a property of explanations is that they are typically taken to be hyperintensional (Thompson 2019), since the strength of an explanation depends not only on its logical structures , but also on how it’s presented and the reasoner's background knowledge. 

Thus, the strength of an explanatory hypothesis H i.e its explanatory power, should be understood as the degree to which one comes to expect E given H, taken relative to the expectedness in E that was prior to reasoning with H.

According to personalism (Dorling & Miller 1981) probabilities can be interpreted as the  doxastic dispositions of degrees of belief  and map onto the reasoner's degree of expectedness in a proposition. An expected fact for a reasoner is one where her degree of expectedness ( degree of belief) and confidence in the fact is high, and so the probability for it is high. A surprising fact is an unexpected fact and the probability for it is low. Thus the explanatory power that I described above can be formalized in terms of probabilities as follows:

```
Explanatory power (EP)  = P(E|H) / P(E), 
```

Where P(E|H) is the probability ( expectedness ) of fact E given the hypothesis H, and P(E) is the prior expectedness of E. 

This captures the notion of explanatory power as the relative change of expectedness in E that H brings about. When P(E|H) > P(E), then EP >1 and H has increased the degree to which one expects E. When P(E|H) =P(E), then EP = 1 and H has no explanatory power and brings about no change in E’s expectedness.


### 3.2 Explanatory power and IBE
This notion of EP is consistent with IBE’s judgments of good (or best) explanations. For instance, Lipton uses an example of an analytic explanation to show that it is not a good explanation in IBE (Lipton 2004).

Explanandum:Why opium tends to put people to sleep.
Analytic explanation: Because opium has dormative power. 

Since this is an analytical explanation, it is a very likely explanation , but it is not a good or a ‘lovely’ explanation since it provides no understanding as to why opium tends to put people to sleep. In terms of EP, since the analytic explanation H is a tautology of explanandum E , it will not bring about any increase in E’s expectedness. The expectedness of E given H remains the same as the prior expectedness of E. Thus EP also judges this to be a poor explanation with no explanatory power in explaining E.

Similarly, a hypothesis that is irrelevant in relation to the explanandum and whose explanatory content has nothing to do with the explanandum, would not serve as a good explanation in IBE. Nor would it in the above formulation of EP. Since H is irrelevant , E and H statistically independent and H has no effect on the likelihood of E,  and so P(E|H)=P(E), which returns EP =1, and thereby the irrelevant hypothesis H has no explanatory power over E. 

As a final comparison, consider Salmon’s (Salmon 1972) example of John Jones who avoids becoming pregnant because he regularly takes birth control pills. The hypothesis of taking birth control pills has a positive effect on the likelihood of not becoming pregnant, it raises the expectedness of pregnancy avoidance and P(E|H) is high. If P(E|H) , the degree of expectedness in E given H, i.e. the likelihood of not becoming pregnant given regular use of birth control pills, was the only measure of EP, then it would diverge from judgements of IBE and incorrectly grant this as an explanation to why John Jones (a cis male) avoids becoming pregnant. But EP is formalized as the ratio of likelihood over prior expectedness. Prior expectedness of Jones not becoming pregnant is 1 i.e P(E) =1 ,so even though P(E|H) is high, EP is not greater than 1 and has no explanatory power here.


### 4. Strong compatibility 
In this section I show that objective bayesianism is equal to the measure of explanatory power derived in the previous section, and thus ensures compatibility with judgments of IBE and locates explanatory considerations of IBE within the bayes theorem. Furthermore in the second subsection I argue that the explanatory virtue of simplicity is inherently implemented in bayesianism.  


### 4.1 Locating explanatory considerations in bayesianism
In the previous section I argued that my formulation of explanatory power as the ratio of likelihood of E given H , over the prior probability of E, where E is the explanandum and H is the hypothesis, is consistent with IBE’s judgment of explanatory goodness to determine good or best explanations.

But this ratio is nothing but the conditionalization component P(E|H) / P(E) of the bayes theorem. Bayesian posterior probability is the prior probability of hypothesis conditionalized on evidence and denoted by the product of P(E|H)/P(E) and prior probability P(H). Supposing objective bayesianism, which implements equal prior probabilities in the hypothesis-space per the principle of indifference (Jaynes & Bretthorst 2003) , then the posterior probability is simply equal to the ratio P(E|H)/P(E). And this is the same as EP, which I showed to be consistent with the judgments of explanatory goodness in IBE . Thus, we have a clear case in objective bayesianism where its judgements on hypotheses not only correspond to judgments of IBE, but a factor that is proportional to explanatory goodness in IBE, can be located as an inherent component of the bayes theorem. 
4.2 Locating the simplicity virtue in bayesianism
Liptons model of IBE argues for an ‘inference to the loveliest explanation’ where the mark of a lovely explanation can be found in explanatory virtues such as simplicity. In this section I argue that bayesianism inherently implements ‘simplicity’ since its likelihood component will always allocate higher probability to the simpler hypothesis.

```
Consider data E  = {16, 8, 2, 64} , numbers drawn one at a time from a sequence of generated data. We start with two competing sequence generator hypotheses, that equally explain this data but differ in complexity by differing in the number of assumptions 

Hypothesis1= random sequence generator that generates only power of two numbers
Hypothesis2= random sequence generator that generates only power of two or even numbers.

Hypothesis2 is the more complex of the two, with an additional assumption of even numbers. Granting objective priors, and that the highest generated number in the sequence is less than 100, the comparative bayesian posterior probabilities of the two hypothesis can be calculated as their likelihood ratios:

P(Hypothesis1 | E) / P(Hypothesis2 | E)  =  P(E|(Hypothesis1) /  P(E|(Hypothesis2)

Hypothesis1 can only generate six numbers that are less than 100. So 6 possible outcomes, and the probability of observing any one of these outcomes is 1 / 6.

Hypothesis2 can generate 50 numbers that are less than 100. So 50 possible outcomes, and the probability of observing any one of these outcomes is 1 / 50.

The draw of E is made one at a time , starting with E= {16}
Then the probability of E given Hypothesis1 is P(E|Hypothesis1)=1 / 6 and the probability of E given Hypothesis2 is P(E|Hypothesis2) = 1 / 50.

After four draws , E= {16, 8, 2, 64},   P(E|Hypothesis1) =  (1/6)^4=0.00077 and P(E|Hypothesis2)= (1/50)^4= 1.6 x 10^-7.
```

The likelihood ratio, which is nothing but the posterior probability ratio,  after four draws is 5000 to 1 in favor of the simpler hypothesis,  Hypothesis1. The key point is this: The simpler hypothesis with less number of assumptions fits or yields a smaller range of outcomes , Hypothesis1 can generate six outcomes versus Hypothesis2’s fifty. Since probability density integrates to one ( or for discrete values the probability mass function sums to 1) (Kolmogorov 1933), the probability of observing any one of its outcomes is 1 / number of possible outcomes, which for Hypothesis1 is 1 / 6 versus 1 / 50 for Hypothesis2. Thus if the simpler hypothesis is true, the likelihood of observing E given Hypothesis1 will always be higher than the likelihood of observing E given Hypothesis2 (Jefferys & Berger 1992). While both Hypothesis1 and Hypothesis2 fit E, Hypothesis1 fits only E and nothing else , while Hypothesis2 fits E and other data as well. This can be understood as Hypothesis1 capturing and explaining the core causal principles while Hypothesis2  capturing additional noise.

Consider another example, we start with two hypotheses , H1 = coin with double-sided heads and H2 = a regular unbiased coin. A coin is flipped ten times and each time it lands on a head. As objective bayesians we start with objective priors, but after ten tries, the likelihood of observing ten heads given H1 is much higher than given H2. In this case again H1 is the simpler hypothesis as it fits or yields a smaller number of possible outcomes ( just one outcome) compared to H2, and if H1 is true ( coin flips continue to yield only heads) , the likelihood ratio and thus the posterior ratio will be in favor of it, even though H2 can generate and fit all the observed outcomes of heads as well.  

Regarding scientific models and tunable parameters, the more tunable parameters there are, the more the model can be adjusted to accommodate data and thus fit or yield a wider range of outcomes. For example consider linear models y = ax, where a is the only tunable parameter versus yhat = b +ax, where a and b are tunable parameters. For the y model, parameter ‘a’ can be tuned to fit  some number of possible outcomes, let's take this to be N possible outcomes. The yhat model has an additional tunable parameter ‘b’, and so both ‘a’ and ‘b’ can be tuned to fit more than N possible outcomes, let’s take this as N+M outcomes. Note the model yhat can fit all of model  y’s N possible outcomes ( at b=0, yhat=y=ax) and then some M possible outcomes. For further illustration note that the y model has to originate from the origin (at x=0, y=0), but yhat can fit more outcomes as it can originate from any tuned value of ‘b’ (at x=0, y=b). 

To evaluate this in objective bayesian terms, 
When y is true and observed data E matches the outcomes of y and yhat,

For model y, the likelihood probability of observing E given y = P(E|y) = 1/N
For model yhat , P(E|yhat) = 1/(N+M)  

Since P(E|y) >  P(E|yhat), the likelihood ratio of P(E|y)/P(E|yhat) and the posterior ratio is greater than 1. Thus bayesianism favors the simpler model y with less number of tunable parameters ( Mackay 2003). 

### 5. Conclusion

Having shown that objective bayesianism is equal to my measure of explanatory power, which is also consistent with explanatory goodness in IBE, I have argued that bayesianism and IBE will usually arrive at similar inferences. My discussions also include locating explanatory considerations of IBE including virtue of simplicity as an inherent part of the bayesian operation, thereby meeting the desiderata of strong compatibilism. 

---

## Bibliography

Gillies. (2000). Philosophical Theories of Probability. Routledge. https://doi.org/10.4324/9780203132241

Lipton. (2004). Inference to the best explanation / Peter Lipton. (Second edition.). Routledge

MacKay. (2004). Information Theory, Inference, and Learning Algorithms. IEEE Transactions on Information Theory, 50(10), 2544–2545. https://doi.org/10.1109/TIT.2004.834752

Vogel, J.(1998). Inference to the best explanation. In The Routledge Encyclopedia of Philosophy. Taylor and Francis. Retrieved 27 Apr. 2022, from https://www.rep.routledge.com/articles/thematic/inference-to-the-best-explanation/v-1. doi:10.4324/9780415249126-P025-1

Fann. (1970). Peirce’s theory of abduction / by K.T. Fann. Martinus Nijhoff.

Huemer. (2009). Explanationist Aid for the Theory of Inductive Logic. The British Journal for the Philosophy of Science, 60(2), 345–375. https://doi.org/10.1093/bjps/axp008

Jaynes, & Bretthorst, G. L. (2003). Probability theory : the logic of science / E.T. Jaynes ; edited by G. Larry Bretthorst. Cambridge University Press.

Goodman. (1965). Fact, fiction and forecast / Nelson Goodman. (Second edition.). Bobbs-Merrill.

Aliseda-LLera. (1997). Seeking explanations: Abduction in logic, philosophy of science and artificial intelligence. ProQuest Dissertations Publishing.

THOMPSON. (2019). Questions and Answers: Metaphysical Explanation and the Structure of Reality. Journal of the American Philosophical Association, 5(1), 98–116. https://doi.org/10.1017/apa.2018.51

Dorling, & Miller, D. (1981). Bayesian Personalism, Falsificationism, and the Problem of Induction. Supplementary Volume - Aristotelian Society, 55(1), 109–141. https://doi.org/10.1093/aristoteliansupp/55.1.109

Weisberg. (2009). Locating IBE in the Bayesian Framework. Synthese, 167(1), 125–143. https://doi.org/10.1007/s11229-008-9305-y

Roger White. (2005). Explanation as a Guide to Induction. Philosophers’ Imprint, 5, 1–.

W. C. SALMON “Statistical Explanation and Statistical Relevance” (Book Review). (1972). Philosophical Books, 13(3), 30–. Basil Blackwell.

Jefferys, & Berger, J. O. (1992). Ockham’s Razor and Bayesian Analysis. American Scientist, 80(1), 64–72.

Kolmogorov, A. N., & Bharucha-Reid, A. T. (2018). Foundations of the theory of probability: Second English Edition. Courier Dover Publications.



